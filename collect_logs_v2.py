# ============================================================
# COLLECT LOGS V2 - –°–±–æ—Ä—â–∏–∫ –ª–æ–≥–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
# ============================================================
# –í–µ—Ä—Å–∏—è: v2.0
# –î–∞—Ç–∞: 02.01.2025
# ============================================================

"""
–°–ë–û–†–©–ò–ö –õ–û–ì–û–í
=============

–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –ª–æ–≥–∏ –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –≤ –æ–¥–∏–Ω ZIP-–∞—Ä—Ö–∏–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python collect_logs_v2.py

–°–æ–∑–¥–∞—ë—Ç —Ñ–∞–π–ª: logs_debug_YYYYMMDD_HHMMSS.zip
"""

import os
import sys
import json
import time
import zipfile
import traceback
from datetime import datetime
from typing import List, Dict, Optional

# –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = BASE_DIR
OUTPUT_DIR = os.path.join(BASE_DIR, "logs_export")


def collect_logs() -> str:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –ª–æ–≥–∏ –∏ —Å–æ–∑–¥–∞—ë—Ç ZIP-–∞—Ä—Ö–∏–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –∞—Ä—Ö–∏–≤—É.
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    archive_name = f"logs_debug_{timestamp}.zip"
    archive_path = os.path.join(OUTPUT_DIR, archive_name)
    
    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    print(f"üîÑ –°–±–æ—Ä –ª–æ–≥–æ–≤...")
    print(f"üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {BASE_DIR}")
    
    files_to_collect = []
    
    # 1. –û—Å–Ω–æ–≤–Ω—ã–µ –ª–æ–≥-—Ñ–∞–π–ª—ã
    log_files = [
        "errors.txt",
        "app.log",
        "trainer_trace.txt",
        "trainer_errors.txt",
        "trades_log.txt",
        "trainer_decisions.jsonl",
    ]
    
    for f in log_files:
        path = os.path.join(BASE_DIR, f)
        if os.path.exists(path):
            files_to_collect.append((path, f"logs/{f}"))
            print(f"  ‚úÖ {f}")
        else:
            print(f"  ‚ö†Ô∏è {f} - –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # 2. –§–∞–π–ª—ã —Å–æ—Å—Ç–æ—è–Ω–∏—è (JSON)
    state_files = [
        "bridge_snapshot.json",
        "trainer_state.json",
        "app_state.json",
        "scanner_state.json",
        "config.json",
    ]
    
    for f in state_files:
        path = os.path.join(BASE_DIR, f)
        if os.path.exists(path):
            files_to_collect.append((path, f"state/{f}"))
            print(f"  ‚úÖ {f}")
        else:
            print(f"  ‚ö†Ô∏è {f} - –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # 3. –õ–æ–≥–∏ –∏–∑ –ø–∞–ø–∫–∏ logs/
    logs_dir = os.path.join(BASE_DIR, "logs")
    if os.path.exists(logs_dir):
        for f in os.listdir(logs_dir):
            if f.startswith("."):
                continue
            path = os.path.join(logs_dir, f)
            if os.path.isfile(path):
                files_to_collect.append((path, f"logs/{f}"))
                print(f"  ‚úÖ logs/{f}")
    
    # 4. ML –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å—Ç—Ä–æ–∫)
    ml_files = [
        ("ml_data/signals.jsonl", 1000),
        ("ml_data/trades.jsonl", 500),
    ]
    
    for rel_path, max_lines in ml_files:
        path = os.path.join(BASE_DIR, rel_path)
        if os.path.exists(path):
            # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å—Ç—Ä–æ–∫
            try:
                with open(path, "r", encoding="utf-8") as f:
                    lines = f.readlines()
                    tail = lines[-max_lines:] if len(lines) > max_lines else lines
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                temp_name = rel_path.replace("/", "_") + f".last{max_lines}"
                temp_path = os.path.join(OUTPUT_DIR, temp_name)
                with open(temp_path, "w", encoding="utf-8") as f:
                    f.writelines(tail)
                
                files_to_collect.append((temp_path, f"ml/{temp_name}"))
                print(f"  ‚úÖ {rel_path} (–ø–æ—Å–ª–µ–¥–Ω–∏–µ {max_lines} —Å—Ç—Ä–æ–∫)")
            except Exception as e:
                print(f"  ‚ùå {rel_path}: {e}")
    
    # 5. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config_files = [
        "core/config.py",
        "core/config_v2.py",
        "core/params.py",
        "params/DEFAULT.json",
    ]
    
    for f in config_files:
        path = os.path.join(BASE_DIR, f)
        if os.path.exists(path):
            files_to_collect.append((path, f"config/{os.path.basename(f)}"))
            print(f"  ‚úÖ {f}")
    
    # 6. –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    sys_info = collect_system_info()
    sys_info_path = os.path.join(OUTPUT_DIR, "system_info.json")
    with open(sys_info_path, "w", encoding="utf-8") as f:
        json.dump(sys_info, f, indent=2, ensure_ascii=False)
    files_to_collect.append((sys_info_path, "system_info.json"))
    print(f"  ‚úÖ system_info.json")
    
    # 7. –°–æ–∑–¥–∞—ë–º ZIP-–∞—Ä—Ö–∏–≤
    print(f"\nüì¶ –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞: {archive_name}")
    
    with zipfile.ZipFile(archive_path, "w", zipfile.ZIP_DEFLATED) as zf:
        for src_path, arc_name in files_to_collect:
            try:
                zf.write(src_path, arc_name)
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ {arc_name}: {e}")
    
    # 8. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    for src_path, arc_name in files_to_collect:
        if src_path.startswith(OUTPUT_DIR) and "last" in src_path:
            try:
                os.remove(src_path)
            except:
                pass
    
    try:
        os.remove(sys_info_path)
    except:
        pass
    
    archive_size = os.path.getsize(archive_path)
    print(f"\n‚úÖ –ê—Ä—Ö–∏–≤ —Å–æ–∑–¥–∞–Ω: {archive_path}")
    print(f"üìä –†–∞–∑–º–µ—Ä: {archive_size / 1024:.1f} KB")
    print(f"üìÅ –§–∞–π–ª–æ–≤ —Å–æ–±—Ä–∞–Ω–æ: {len(files_to_collect)}")
    
    return archive_path


def collect_system_info() -> Dict:
    """–°–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ."""
    info = {
        "timestamp": datetime.now().isoformat(),
        "python_version": sys.version,
        "platform": sys.platform,
        "cwd": os.getcwd(),
        "base_dir": BASE_DIR,
    }
    
    # –í–µ—Ä—Å–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–∏–∑ README –∏–ª–∏ TZ)
    try:
        tz_path = os.path.join(BASE_DIR, "TZ_FULL_v309.txt")
        if os.path.exists(tz_path):
            with open(tz_path, "r", encoding="utf-8") as f:
                first_line = f.readline().strip()
                info["project_version"] = first_line[:100]
    except:
        pass
    
    # –†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    state_files = ["bridge_snapshot.json", "trainer_state.json"]
    for f in state_files:
        path = os.path.join(BASE_DIR, f)
        if os.path.exists(path):
            info[f"{f}_size"] = os.path.getsize(path)
            info[f"{f}_mtime"] = datetime.fromtimestamp(
                os.path.getmtime(path)
            ).isoformat()
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –æ—à–∏–±–∫–∏
    errors_path = os.path.join(BASE_DIR, "errors.txt")
    if os.path.exists(errors_path):
        try:
            with open(errors_path, "r", encoding="utf-8") as f:
                lines = f.readlines()
                info["errors_count"] = len([l for l in lines if l.startswith("=")])
                info["last_error_line"] = lines[-1].strip() if lines else ""
        except:
            pass
    
    return info


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("=" * 60)
    print("üìã –°–ë–û–†–©–ò–ö –õ–û–ì–û–í v2.0")
    print("=" * 60)
    print()
    
    try:
        archive_path = collect_logs()
        
        print()
        print("=" * 60)
        print("‚úÖ –ì–û–¢–û–í–û!")
        print(f"üì¶ –ê—Ä—Ö–∏–≤: {archive_path}")
        print()
        print("–û—Ç–ø—Ä–∞–≤—å—Ç–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        print("=" * 60)
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
